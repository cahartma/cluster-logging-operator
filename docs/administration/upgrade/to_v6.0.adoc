:toc:
:toclevels: 4

= What's New In Logging 6.0

== Overview
Logging version 6.0 is a major change from earlier releases and is the realization of several longstanding goals.

The main highlights of these changes are:

* There are now distinct operators to support each separate logging components (e.g. collectors, storage, visualization)
* The ClusterLoggingOperator no longer manages log storage or visualization of any kind including LokiStack resource or Elastic products (i.e. Elasticsearch, Kibana)
* CLO has removed support of Fluentd log collector implementation
* Introduce the `ClusterLogForwarder.observability.openshift.io` API to replace both `ClusterLogging.logging.openshift.io` and `ClusterLogForwarder.logging.openshift.io` APIs

.5.x
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogging
----
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
----

Replaced with:

.6.0
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
----

NOTE: There is no automated upgrade provided by the *cluster-logging-operator*

Given the numerous combinations in which log collection, forwarding, and storage can be configured, there is no automated upgrade provided by the *cluster-logging-operator*.  The following documentation is intended to assist administrators in converting exising **ClusterLogging.logging.openshift.io** and **ClusterLogForwarder.logging.openshift.io** specifications to the new API.  This document includes example of migrated **ClusterLogForwarder.observability.openshift.io** resources for several common use cases.

== Changes

Cluster Logging no longer provides a "one click" installation of a complete logging solution in favor of administrators
having more granular control over individual components.  This means administrators must explicitly deploy an operator to control
a given component. The general steps for deploying a complete logging solution are:

1. Deploy the Red Hat **cluster-observability-operator**
2. Deploy the Red Hat **loki-operator**
3. Create an instance of **LokiStack** in the *openshift-logging* namespace
4. Deploy the Red Hat **cluster-logging-operator**
5. Create an instance of the **ClusterLogForwarder.observability.openshift.io** resource

=== Log Storage
The only available managed log storage solution for this release is a Loki stack that is based upon the **loki-operator**.  This
solution was available in prior releases as the preferred alternative to the managed Elasticsearch offering.  The deployment
of this solution remains unchanged from previous releases. Read the https://docs.openshift.com/container-platform/4.16/observability/logging/log_storage/installing-log-storage.html[official] product documentation for more information.

NOTE: To continue to use an existing Red Hat managed Elasticsearch deployment provided by the **elasticsearch-operator**,
remove the owner references from the **Elasticsearch** resource named '**elasticsearch**' in the '**openshift-logging**'
namespace before removing the **ClusterLogging** resourced named '**instance**' in the '**openshift-logging**' namespace

=== Log Visualization
The OpenShift console UI plugin that provides visualization was moved to the **cluster-observability-operator** from the
**cluster-logging-operator**. Read the https://docs.openshift.com/container-platform/4.16/observability/cluster_observability_operator/installing-the-cluster-observability-operator.html[official] product documentation
for more information.

NOTE: To continue to use an existing Red Hat managed Kibana deployment provided by the **elasticsearch-operator**,
remove the owner references from the **Kibana** resource named '**kibana**' in the '**openshift-logging**'
namespace before removing the **ClusterLogging** resourced named '**instance**' in the '**openshift-logging**' namespace

=== Log Collection & Forwarding

Log collection and forwarding configuration is spec'd from a new link:../../reference/operator/api_observability_v1.adoc[API]
that is included in the API group **observability.openshift.io**. The following sections highlight the differences from the
https://github.com/openshift/cluster-logging-operator/blob/release-5.9/docs/reference/operator/api.adoc[old API] resource.

NOTE: Vector is the only supported collector implementation.

==== Permissions

This release of Cluster Logging requires a service account to be specified.  Administrators must now *explicitly grant log collection permissions* to the service account associated with *ClusterLogForwarder*.  This was not required in previous releases for the legacy logging scenario consisting of a *ClusterLogging* and, optionally, a *ClusterLogForwarder.logging.openshift.io* resource.

[source, yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: my-forwarder
spec:
  serviceAccount:
    name: logcollector
----
Using the existing service account (i.e. *logcollector*) from a previous release requires creating the following *ClusterRoleBinding*:

----
oc adm policy add-cluster-role-to-user collect-application-logs -z logcollector
oc adm policy add-cluster-role-to-user collect-infrastructure-logs -z logcollector
----

Additionally, create the following *ClusterRoleBinding* if collecting audit logs:

----
oc adm policy add-cluster-role-to-user collect-audit-logs -z logcollector
----

==== Management, Resource Allocation & Workload Scheduling
Configuration of the management state (i.e. managed, unmanaged), resource request and limits, tolerations, and node selection
are part of the new ClusterLogForwarder API.

.Previously part of 'ClusterLogging' (5.9)
[source, yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogging
spec:
  managementState: Managed
  collection:
    resources:
      limits: {}
      requests: {}
    nodeSelector: {}
    tolerations: {}
----
.Now spec'd in the 6.0 'ClusterLogForwarder' along with inputs, outputs, filters and pipelines
[source, yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
spec:
  managementState: Managed
  collector:
    resources:
      limits: {}
      requests: {}
    nodeSelector: {}
    tolerations: {}
...
----

==== Input Specifications

The input spec is an optional part of the *ClusterLogForwarder* spec where administrators can continue to use the pre-defined values of *application*, *infrastructure*, and *audit* to collect those sources. See the
https://github.com/openshift/enhancements/blob/master/enhancements/cluster-logging/logs-observability-openshift-io-apis.md#api-extensions[enhancement] document for definitions of these values.  The spec, otherwise, has largely remained unchanged.

===== Application Inputs
Namespace and container inclusion and exclusions were collapsed into a single field

.5.9 Application Input with Namespace and Container Includes and Excludes
[source, yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
spec:
  inputs:
   - name: app-logs
     type: application
     application:
       namespaces:
       - foo
       - bar
       includes:
       - namespace: my-important
         container: main
       excludes:
       - container: too-verbose
       containerLimit:
         maxRecordsPerSecond: 500
----

.6.0 Application Input with Namespace and Container Includes and Excludes
[source, yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
spec:
  inputs:
   - name: app-logs
     type: application
     application:
       includes:
       - namespace: foo
       - namespace: bar
       - namespace: my-important
         container: main
       excludes:
       - container: too-verbose
       tuning:
          rateLimitPerContainer:
            - maxRecordsPerSecond: 500
----

NOTE: *application*, *infrastructure*, and *audit* are reserved words and can not be used for the name when defining an input

===== Input Receivers

Input receiver changes:

* Explicit configuration of the type at the receiver level
* Moves the port to the receiver level.

.5.9 Input Receivers
[source, yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
spec:
  inputs:
  - name: an-http
    receiver:
      http:
        port: 8443
        format: kubeAPIAudit
  - name: a-syslog
    receiver:
      type: syslog
      syslog:
        port: 9442
----

.6.0 Input Receivers
[source, yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
spec:
  inputs:
  - name: an-http
    type: receiver
    receiver:
      type: http
      port: 8443
      http:
        format: kubeAPIAudit
  - name: a-syslog
    type: receiver
    receiver:
      type: syslog
      port: 9442
----

==== Output Specifications

The high-level output spec changes:

* Moves URL to each output type spec
* Moves tuning to each output type spec
* Separates TLS from authentication
* Requires explicit configuration of keys and secret/configmap for TLS and authentication

==== Secrets & TLS Configuration
Secrets and TLS configuration are separated into authentication and TLS configuration for each output. They
are now explicitly defined in the specification instead of relying upon
administrators to define secrets with recognized https://github.com/openshift/cluster-logging-operator/blob/release-5.9/docs/reference/operator/secrets.adoc[keys].

Upgrading TLS and authorization configuration will require administrators to understand the previously recognized
keys in order to continue to use existing secrets. Examples in the following sections will provide details
how to configure a ClusterLogForwarder secrets to forward to existing Red Hat managed log storage solutions.

===== Red Hat Managed Elasticsearch
.v5.9 Forwarding to Red Hat Managed Elasticsearch
[source, yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  logStore:
    type: elasticsearch
----

.v6.0 Forwarding to Red Hat Managed Elasticsearch
[source, yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  serviceAccount:
    name: my-account
  outputs:
    - name: default-elasticsearch
      type: elasticsearch
      elasticsearch:
        url: https://elasticsearch:9200
        version: 6
        index: '{.log_type||"unknown"}-write'   <1>
      tls:
        ca:
          key: ca-bundle.crt
          secretName: collector
        certificate:
          key: tls.crt
          secretName: collector
        key:
          key: tls.key
          secretName: collector
  pipelines:
    - name: my-pipeline
      outputRefs:
        - default-elasticsearch
      inputRefs:
        - application
        - infrastructure
----
. `index` can be a combination of dynamic and static values. Dynamic values are enclosed in curly brackets `{}`
and MUST end with a "quoted" static fallback value separated with `||`.

More details use: `oc explain clf.spec.outputs.elasticsearch.index`


NOTE: In this example, application logs are written to the 'application-write' and 'infrastructure-write' index.
Previous versions without the `index` spec, would have instead written to 'app-write', 'infra-write'.


===== Red Hat Managed LokiStack
.v5.9 Forwarding to Red Hat Managed LokiStack
[source, yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  logStore:
    type: lokistack
    lokistack:
      name: logging-loki
----

.v6.0 Forwarding to Red Hat Managed LokiStack
[source,yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  serviceAccount:
    name: logcollector
  outputs:
  - name: default-lokistack
    type: lokiStack
    lokiStack:
      target:
        name: logging-loki
        namespace: openshift-logging
      authentication:
        token:
          from: serviceAccount
    tls:
      ca:
        key: service-ca.crt
        configMapName: openshift-service-ca.crt
  pipelines:
  - name: my-pipeline
    outputRefs:
    - default-lokistack
    inputRefs:
    - application
    - infrastructure
----

==== Filters & Pipeline Configuration
Pipeline configuration only provides defines routing of input sources to their output destination with any transformations needed in between.  All attributes of pipelines in previous releases have been converted to
filters in this release.  Individual filters are defined in the "filters" spec and referenced by a pipeline

.5.9 Filters
[source, yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
spec:
  pipelines:
  - name: app-logs
    detectMultilineErrors: true
    parse: json
    labels:
      foo: bar
----

.6.0 Filter Configuration
[source, yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
spec:
  filters:
  - name: my-multiline
    type: detectMultilineException
  - name: my-parse
    type: parse
  - name: my-labels
    type: openshiftLabels
    openshiftLabels:
      foo: bar
  pipelines:
  - name: app-logs
    filterRefs:
    - my-multiline
    - my-parse
    - my-labels
----
NOTE: Drop filter, Prune filter and KubeAPIAudit filters remain unchanged
[source, yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
spec:
  filters:
  - name: drop-debug-logs
    type: drop
    drop:
    - test:
      - field: .level
        matches: debug
  - name: prune-fields
    type: prune
    prune:
      in:
      - .kubernetes.labels.foobar
      notIn:
      - .message
  - name: audit-logs
    type: kubeAPIAudit
    kubeAPIAudit:
      omitResponseCodes:
      - 404
      - 409
----
==== Validation & Status
Most validations are enforced when a resource is created or updated which provides immediate feedback.  This is
a departure from previous releases where all validation occurred post creation requiring inspection of the resource status location.  Some validation still occurs post resource creation for cases where is not possible to do so at creation or update time.

Instances of the **ClusterLogForwarder.observability.openshift.io** must satisfy the following before
the operator will deploy the log collector:

- *Resource Status Conditions:* `Authorized, Valid, Ready`

- *Spec Validations:* `Filters, Inputs, Outputs, Pipelines`

All must evaluate to `status: "True"`

.6.0 Status "True" Conditions Example
[source, yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
status:
  conditions:
  - message: "permitted to collect log types: [application]"
    reason: ClusterRoleExists
    status: "True"
    type: observability.openshift.io/Authorized
  - message: ""
    reason: ValidationSuccess
    status: "True"
    type: observability.openshift.io/Valid
  - message: ""
    status: "True"
    type: observability.openshift.io/Ready
  filterConditions:
  - message: filter "my-parse" is valid
    reason: ValidationSuccess
    status: "True"
    type: observability.openshift.io/ValidFilter-my-parse
  inputConditions:
  - message: input "application" is valid
    reason: ValidationSuccess
    status: "True"
    type: observability.openshift.io/ValidInput-application
  outputConditions:
  - message: output "rh-loki" is valid
    reason: ValidationSuccess
    status: "True"
    type: observability.openshift.io/ValidOutput-rh-loki
  pipelineConditions:
  - message: pipeline "app-logs" is valid
    reason: ValidationSuccess
    status: "True"
    type: observability.openshift.io/ValidPipeline-app-logs
----

NOTE: Conditions that are satisfied have a "status" value of "True".  Conditions that
have a "status" other than "True" provide a reason and a message identifying the failure.

.6.0 Status "False" Example
[source, yaml]
----
status:
  conditions:
  - message: insufficient permissions on service account, not authorized to collect 'application' logs
    reason: ClusterRoleMissing
    status: "False"
    type: observability.openshift.io/Authorized
  - message: ""
    reason: ValidationFailure
    status: "False"
    type: Ready
----

== Examples & Common Use Cases

=== Forwarding to CloudWatch

====
.Forwarding to CloudWatch using long-lived static key and secret
[source, yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: my-forwarder
spec:
  serviceAccount:
    name: my-account
  outputs:
  - name: my-cw
    type: cloudwatch
    cloudwatch:
      groupName: my-cluster-{.log_type||"unknown"}
      region: us-east-1
      authentication:
        type: awsAccessKey
        awsAccessKey:
          keyId:
            secretName: cw-secret
            key: aws_access_key_id
          keySecret:
            secretName: cw-secret
            key: aws_secret_access_key
  pipelines:
    - name: my-cw-logs
      inputRefs:
        - application
        - infrastructure
      outputRefs:
        - my-cw
----
.Alternative CW Auth spec using Short-Lived Token (SA Token)
[source, yaml]
----
      authentication:
        type: iamRole
        iamRole:
          roleARN:
            secretName: role-for-sts
            key: credentials
          token:
            from: serviceAccount
...
----
.Alternative CW Auth spec using role and static token
[source, yaml]
----
      authentication:
        type: iamRole
        iamRole:
          roleARN:
            secretName: role-for-sts
            key: credentials
          token:
            from: secret
            secret:
              key: token
              name: cw-token
...
----
====
=== Forwarding to the Red Hat Managed Elasticsearch
====

.v5 ClusterLogging
[source, yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  logStore:
    type: elasticsearch
    elasticsearch:
      nodeCount: 3
      resources:
        requests:
          memory: 2Gi
      redundancyPolicy: ZeroRedundancy
  visualization:
    type: kibana
    kibana:
      replicas: 1
  collection:
    type: vector
----
.v5 ClusterLogForwarder
[source, yaml]
----
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  outputs:
    - name: default
      type: elasticsearch
      elasticsearch:
        enableStructuredContainerLogs: true
        structuredTypeKey: kubernetes.namespace_name
        structuredTypeName: nologformat
  pipelines:
    - inputRefs:
        - application
      name: to-default
      parse: json
      outputRefs:
        - default
----
.v6 ClusterLogForwarder
[source, yaml]
----
apiVersion: observability.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  serviceAccount:
    name: logcollector
  outputs:
    - name: es-managed
      type: elasticsearch
      elasticsearch:
        url: https://elasticsearch:9200
        version: 6
        index: '{.kubernetes.namespace_name||"nologformat"}-write'
      tls:
        ca:
          key: ca-bundle.crt
          secretName: collector
        certificate:
          key: tls.crt
          secretName: collector
        key:
          key: tls.key
          secretName: collector
  filters:
    - name: my-parse
      type: parse
  pipelines:
    - name: my-pipeline
      inputRefs:
        - application
      filterRefs:
        - my-parse
      outputRefs:
        - es-managed
----
